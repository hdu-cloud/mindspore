#parallel predict
poisson_model.pb;4;800,1:800,1:800,217:800,1;;parallel_predict 0.5
browser_deepfm_v7.pb;2;200,94:200,94;;parallel_predict 0.5
bert_mindir.mindir;3;1,128:1,128:1,128;;parallel_predict 2.5
wide_deep_model_weight16000_2.pb;2;16000,39:16000,39;;parallel_predict 0.5
roberta_minir_graph.mindir;1;1,32;;parallel_predict 53
browser_scene1_v2.pb;1;75,19910;;parallel_predict 0.5
LaBSE.onnx;2;1,32:1,32;;parallel_predict 5
XLMR/model.onnx;2;1,32:1,32;;parallel_predict 14
#tf model from models_tf.cfg
mnasnet_1.0_224.pb;1:input;1,224,224,3;;parallel_predict 0.5
scan_hms_detect.pb;1:normalized_input_image_tensor;1,320,320,1;;parallel_predict 0.5
hiai_cpu_face_emotion.pb;1:input_0;1,224,224,1;;parallel_predict 0.5
hiai_cpu_face_headpose.pb;1:input_0;1,256,256,3;;parallel_predict 0.5
hiai_cv_focusShootOCRModel_02.pb;1:input_0;1,32,512,1;;parallel_predict 0.5
hiai_latin_ocr.pb;1:input_0;1,32,1024,1;;parallel_predict 0.5
deepaudio.onnx;1;5,80,80;;parallel_predict 0.5
sad_conformer4_output128lu512.pb;3;1,128512,1:1,397,128:1,199;;parallel_predict 0.5
